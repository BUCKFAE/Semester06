\documentclass{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{amsthm}
\usepackage[german,vlined,longend]{algorithm2e}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{mathabx}

\title{DataMining CheatSheet}
\author{Julian Schubert}

% Definition
\mdfdefinestyle{theoremstyle}{
    linecolor=blue!20,
    linewidth=2pt,
    frametitlerule=true,
    frametitlebackgroundcolor=gray!20,
    innertopmargin=\topskip
}
\mdtheorem[style=theoremstyle]{definition}{Definition}

% Eigenschaft
\mdfdefinestyle{eigenschaftstyle}{
    linecolor=red!50,
    linewidth=2pt,
    frametitlerule=true,
    frametitlebackgroundcolor=gray!20,
    innertopmargin=\topskip
}
\mdtheorem[style=eigenschaftstyle]{eigenschaft}{Eigenschaft}


% Kopf- / Fußzeile
\makeatletter
\let\runauthor\@author
\let\runtitle\@title
\pagestyle{fancy}
\fancyhf{}
\rhead{\runtitle}
\lhead{\runauthor}
\cfoot{\thepage}

\newcommand{\subsubsubsection}[1]{\paragraph{#1}\mbox{}\\}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\begin{document}

\maketitle

\section{Gütemaße}
\subsection{Davies-Bouldin Index (DB)}
    \begin{tabular}{| c | c |}
        \hline
        Güte innerhalb des Clusters $C_i$ 
            & $S_i \sqrt[q]{\frac{1}{|C_i|} \sum_{x \in C_i}\text{dist}(x, \mu_i)^q}$ \\
        \hline
        Güte Trennung $C_i$ und $C_j$
            & $M_{i,j} = $dist$(\mu_i, \mu_j)$ \\
        \hline
        $R_{i,j}$ für $i \neq j$
            & $R_{i, j} = \frac{S_i + S_j}{M_{i, j}}$ \\
        \hline
        Davis-Bouldin Index
            & $DB = \frac{1}{k} \sum_{i = 1}^k D_i$ mit $D_i = \max_{i \neq j} R_{i,j}$ \\
        \hline
    \end{tabular}
\section{Distanzfunktionen}
\subsection{Distanzfunktionen für Cluster}
    \begin{tabular}{| c | c |}
        \hline
        Single Link 
            & dist - sl(X, Y) = $\min_{x \in X, y \in Y}$ dist(x, y) \\
        \hline
        Complete Link
            & dist - cl(X, Y) = $\max_{x \in X, y \in Y}$ dist(x, y) \\
        \hline
        Average Link
            & dist - al(X, Y) = $\frac{1}{|X| \cdot |Y|} \cdot \sum_{x \in X, y\in Y}$ dist(x, y) \\
        \hline
    \end{tabular}

\section{OPTICS}
Beschreibung in Worten: 
\begin{enumerate}
    \item Über alle Punkte iterieren
    \item Wenn Punkte im Umkreis vom aktuellen Punkt liegen Distanzen updaten
    \item Alle Nachbarn vom Punkt abarbeiten
    \item Sortiert in die Liste einfügen
\end{enumerate}
\section{Assoziationsregeln}
\begin{itemize}
    \item \textbf{Support}: $supp_D(X) = \frac{|\{ T \in D |X \subseteq T\}|}{|D|}$
    \item \textbf{Frequency:} $supp_X(D) \cdot |D|$
    \item \textbf{Confidence:} $conf_D(X \rightarrow Y) = \frac{supp_D(X \cup Y)}{supp_D(X)}$
\end{itemize}
\section{Auswahl von Assoziationsregeln}
\subsection{Added Value}
\begin{center}
    $
        \frac{sup (A \land B)}{sup (A)} - sup(B) = conf(A \rightarrow B) - sup(B)
    $
\end{center}
Um wie viel steigt die Wahrscheinlichkeit von B, wenn die Bedingung A
Hinzugefügt wird?
\subsection{Kriterien für Interessantheitsmaße}
\begin{enumerate}
    \item Conciseness: \\
    Kürzere Regeln sind besser (weniger Items)
    \item Generality: \\
    Generelle Regeln sind besser (mehr Fälle abgedeckt)
    \item Reliability: \\
    Hohe confidence / accuracy ist besser
    \item Diversity: \\
    Regeln sollten untereinander unähnlich sein
    \item Novelty: \\
    Vorher unbekannt, nicht aus anderen Regeln ableitbar
    \item Surprisingness / Unexpectedness: \\
    Gute Regeln widersprechen Vorwissen / Erwartungen
    \item Applicability: \\ 
    Kann praktisch (in der Anwendung) umgesetzt werden
\end{enumerate}
\subsection{Monotonie}
\begin{itemize}
    \item \textbf{Monotonie}: If a set S violates C, its supersets
    \textbf{might not} violate C, while its subsets \textbf{must}
    violate C
    \item \textbf{Anti-Monotonie}: If a set S violates C, its supersets
    \textbf{must} violate C, while its subsets \textbf{might not}
    violate C
\end{itemize}
\section{Hierarchische Assoziationsregeln}
\begin{itemize}
    \item \textbf{Definition} Hierarchische Assoziationsregel: \\
    $X \Rightarrow Y$, mit $X \subseteq I, Y \subseteq I, X \cap Y = \emptyset$ \\
    Kein Item in Y ist sVorfahre eines Items in X (bezüglich H)
    \item \textbf{Support s} einer hierarchischen Assoziationsregel
    $X \Rightarrow Y$ in D: \\
    Support der Menge $X \cup Y$
    \item \textbf{Konfidenz c} einer hierarchischen Assoziationsregel
    $X \Rightarrow Y$ in D: \\
    Prozentsatz der Transaktionen, die auch die Menge Y unterstützen,
    in der Teilmenge aller Transaktionen, welche die Menge X unterstützen
\end{itemize}
\section{Gütemaße für Klassifikation}
\textbf{K}: Klassifikator, \textbf{TR} Trainingsmenge, \textbf{TE} 
Testmenge
\begin{itemize}
    \item \textbf{Klassifikationsgenauigkeit} $G_{TE}$: \\
    Alles was aus dem Testset richig klassifiziert wurde
    \item \textbf{Tatsächlicher Klassifikationsfehler} $F_{TE}$: \\
    Alles was aus dem Testset falsch klassifiziert wurde
    \item \textbf{Beobachteter Klassifikationsfehler} $F_{TR}$: \\
    Alles was aus dem Trainingsset falsch klassifiziert wurde
\end{itemize}
\section{Precision und Recall}
\textbf{Precision}: $\frac{\text{True positive}}{\text{True Positive} + 
\text{false Positive}}$ \\
Wenn die klasse vorhergesagt wird, wie sicher ist die Vorhersage \\
\\
\textbf{Recall}: $\frac{\text{True positive}}{\text{True Positive} + 
\text{False Negative}}$ \\
Wie oft wird die Klasse c wieder gefunden
\end{document}