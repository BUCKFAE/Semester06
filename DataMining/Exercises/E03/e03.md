# Übung 03

# Aufgabe 1
## 1.1
K-Keans hat die Clusterzentren als average der Punkte um den Punkt selbst herum, bei k-Mediods wird ein echter Punkt als Zentrum ausgewählt. <br>
Laufzeit: <br>
k-Mens: O(n) pro Iteration, im schnitt nur 5-10 Iteratioen<br>
k-Mediods: O(n^3) 

## 1.2
Ja, da wir kategorielle Attribute ebenfalls vergleichen können (zum Beispiel Hamming)

## 1.3
Bestimmen wie gut ein clustering ist das nicht von k abhängt

## 1.4
Für ein festes k, oder wenn wir k herausrechnen (das geht da k monoton fällt)

## 1.5
Jeder Punkt gehört nicht zu einem Festen Cluster, sondern gehört mit einer gewissen Wahrscheinlichkeit zu einem Cluster. <br>
Dann wird für jeden Punkt die Wahrscheinlichkeit berechenet das dieser zu jenem Cluster gehört. 

## 1.6
Man bekommt keine Cluster im eigentlichen Sinne, sondern nur eine Wahrscheinlichkeitsverteilung für jeden Punkt, die angibt mit welcher Wahrscheinlichkeit der Punkt zu welchem Cluster gehört

## 1.7
Alle Punkte, Maximale Distanz die ein Punkt von Clusterzentrum weg sein darf um zum 
Cluster zu gehörten (bzw von einem Punkt im Cluster) und wie viele Punkte sich mindestens in einem Cluster befinden müssen. <br>
Man fügt zu einem Cluster alle Punkte hinzu, die näher als epsilon an einem der 
Punkte im Cluster liegen

## 1.8
Alles in einem Cluster bei max distanz, oder nichts in einem Cluster (alles noise) bei sehr großem MinPts oder sehr kleiner min distanz.

## 1.9
Wird zufällig ausgewählt (resultP.ClID IN {UNCLASSIFIED, NOISE})

## Aufgabe 2
